# job metadata
owner: svc.lore
type: preprocessing
version: 0
is_enabled: True

# VertexAI Project spec
project: dp-lore
bq_project: dp-lore
location: us-central1

# VertexAI Custom Job spec
display_name: shoplikelihood_v4_dl_
script_path: mlmodels/ctr_shoplikelihood_v4/train_dl.py
container_uri: us-docker.pkg.dev/vertex-ai/training/sklearn-cpu.1-6:latest
requirements:
  - python-json-logger>=2.0.2
  - bigframes==0.22.0
  - ibis-framework>=7.1.0,<8.0.0
  - sqlglot>=18.12.0,<20
  - pyarrow>=10,<18
  - fastparquet
  - pandas>=1.5,<2.2
  - gcsfs
  - ruamel.yaml
  - db-dtypes
  - google-cloud-bigquery[bqstorage]>=3.10.0
  - google-api-python-client>=2.0.0
  - imbalanced-learn>=0.10
  - optuna>=3.0.0
  - tensorflow>=2.12.0
  # - xgboost>=2.0.0
  # - lightgbm>=4.0.0
  # - scikit-learn>=1.0.2
  # - shap>=0.41.0
  # - optuna-integration[xgboost]
  # - catboost>=1.2
# - tensorflow>=2.12.0
replica_count: 1
machine_type: n2-highmem-80
accelerator_type: ACCELERATOR_TYPE_UNSPECIFIED
accelerator_count: 4
boot_disk_type: pd-ssd
boot_disk_size_gb: 500
staging_bucket: gs://hybrid_recom_lightfm_bucket/ctr/model_registry/non_offer_view_first_segment
timeout: 36000
enable_web_access: True

# Optional: environment knobs for better GPU utilization and stability
# env:
#   TF_ENABLE_AUTO_MIXED_PRECISION: "1"   # pairs with tf.keras.mixed_precision.set_global_policy("mixed_float16")
#   TF_FORCE_GPU_ALLOW_GROWTH: "true"     # avoid upfront VRAM grab
#   TF_GPU_ALLOCATOR: "cuda_malloc_async" # reduces fragmentation on long runs
#   NCCL_DEBUG: "WARN"

# Metadata Logging spec, BigQuery Table
job_metadata_table_path: hybrid_recom_lightfm_ctr.cia_vertexai_job_metadata